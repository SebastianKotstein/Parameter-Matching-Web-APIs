{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db764115-9c86-404c-bda7-536740ef8768",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46202d2d-73a7-43c3-872d-eecc5ddef256",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d24e41-6ef1-4fdb-8964-f65b1b8e2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ac28f-6a2a-46f7-836a-ae051ee810a6",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bfa97-ed47-4252-81a4-0328362a00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import operator\n",
    "import os\n",
    "\n",
    "# tqdm is used to visualize the progress while processing input files\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for embedding current time into log file name \n",
    "from datetime import datetime\n",
    "\n",
    "# We will use a pre-trained tokenizer to determine the length of strings\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146f744-113e-4727-8cf3-03c94b468160",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0df4f-fa6a-4149-95fa-ed3849cdc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if set, only the first 'n' API tree models will be loaded\n",
    "api_limit = None\n",
    "\n",
    "remove_uris = True  # remove URIs from description\n",
    "sort_by_name = True # sort context by name\n",
    "\n",
    "max_depth = 8 # max. depth of XPath in both context and answer\n",
    "min_question_length = 3 # min. number of tokens that must be in a question\n",
    "max_question_length = 96 # max. number of tokens that may be in a question\n",
    "\n",
    "max_questions_per_sample = 32 # max. number of Question-Answer pairs per sample. If number is exceeded, additional sample is created\n",
    "\n",
    "number_of_chunks = 10 # number of containers where samples are distributed to\n",
    "\n",
    "# Variable that specifies how many times the generated sample set is repeated. A value of '1' means that each sample is only created once.\n",
    "original_retakes = 1\n",
    "shuffled_retakes = 0\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Specify the base model that is used for training later. We will use its pre-trained tokenizer in this notebook.\n",
    "base_model = \"microsoft/codebert-base\"\n",
    "\n",
    "# List of special tokens that should be removed from XPaths while creating context string\n",
    "to_be_removed = [\"<?>\",\"<str>\",\"<num>\",\"<int>\",\"<bool>\",\"{_}\",\"$.\"]\n",
    "\n",
    "input_path = \"/home/user/input_directory/\"\n",
    "output_path = \"/home/user/output_directory/\"\n",
    "\n",
    "# APIs (identified by their keys) that should be excluded from processing after loading and parsing them (e.g. due to too many payloads)\n",
    "excluded_api_keys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807b27b-ad26-43d2-9a6f-7b3bb1d61c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_no_context = 0\n",
    "cnt_no_property_description = 0\n",
    "cnt_too_short_property_description = 0\n",
    "cnt_too_long_property_description_but_truncated = 0\n",
    "cnt_too_long_property_description = 0\n",
    "cnt_too_deep_property_xpath = 0\n",
    "cnt_split_samples = 0\n",
    "cnt_answer_not_in_context = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8570ec-cf40-49a7-b65e-e1c4f6c44914",
   "metadata": {},
   "source": [
    "# Load and Parse API Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a423970-e75f-43c2-9956-a9011f131f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_data_types_from_xpath(xpath: str):\n",
    "    \"\"\"\n",
    "    Removes special tokens defined in 'to_be_removed' from the passed XPath (input string) and returns the modified string\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xpath : str\n",
    "        input string\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Modified input string\n",
    "    \"\"\"\n",
    "    for data_type in to_be_removed:\n",
    "        xpath = xpath.replace(data_type,\"\")\n",
    "    return xpath\n",
    "\n",
    "\n",
    "class ApiInterfaceNode:\n",
    "    \"\"\"\n",
    "    Represents a generic node in an API tree.\n",
    "    ...\n",
    "    Attributes\n",
    "    ----------\n",
    "    key : str\n",
    "        key that uniquely identifies the node among all children of the parent node\n",
    "    value\n",
    "        optional value of the node\n",
    "    node_type: str\n",
    "        type (i.e. role) of the node, allowed values are 'api', 'path', 'method', 'response', 'payload', and 'property'\n",
    "    id : str\n",
    "        unique identifier of the node among all nodes of the API tree\n",
    "    elements : ApiInterfaceNode\n",
    "        contains all children of the node\n",
    "    raw_node\n",
    "        contains the original JSON structure of the node and the sub tree as Python dictionary\n",
    "    api_key : str\n",
    "        contains the API key, this attribute is only present if node is type of 'api'\n",
    "    api_name: str\n",
    "        contains the API name, this attribute is only present if node is type of 'api'\n",
    "    api_version_key : str\n",
    "        contains the API version key, this attribute is only present if node is type of 'api'\n",
    "    api_version_name : str\n",
    "        contains the API version name, this attribute is only present if node is type of 'api'\n",
    "    method_summary : str\n",
    "        contains the summary of the method, this attribute is only present if node is type of 'method'\n",
    "    method_description : str\n",
    "        contains the description of the method, this attribute is only present if node is type of 'method'\n",
    "    response_description : str\n",
    "        contains the description of the response, this attribute is only present if node is type of 'response'\n",
    "    property_name : str\n",
    "        contains the name of the property, this attribute is only present if node is type of 'property'\n",
    "    property_data_type : str\n",
    "        contains the data type of the property, this attribute is only present if node is type of 'property'\n",
    "    property_xpath : str\n",
    "        contains the XPath of the property, this attribute is only present if node is type of 'property'\n",
    "    property_format : str\n",
    "        contains the format of the property, this attribute is only present if node is type of 'property'\n",
    "    property_pattern : str\n",
    "        contains the pattern of the property, this attribute is only present if node is type of 'property'\n",
    "    property_description : str\n",
    "        contains the description of the property, this attribute is only present if node is type of 'property'\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    is_type(node_type : str):\n",
    "        Returns true if the node's type is equal the passed type\n",
    "    __str__(): \n",
    "        Returns a JSON object as string containing all attributes of the node\n",
    "    \"\"\"\n",
    "    def __init__(self, api_documentation_raw_node):\n",
    "        \"\"\"\n",
    "        Constructs the sub tree consisting of ApiInterfaceNodes based on the passed raw API tree model (parsed JSON structrure as Python dictionary).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        api_documentation_raw_node\n",
    "            parsed JSON structure of the API tree model as Python dictionary\n",
    "        \"\"\"\n",
    "        self.raw_node = api_documentation_raw_node\n",
    "\n",
    "        # Generic attributes\n",
    "        self.key = api_documentation_raw_node[\"key\"]\n",
    "        self.value = api_documentation_raw_node[\"value\"]\n",
    "        self.node_type = api_documentation_raw_node[\"type\"]\n",
    "        self.id = api_documentation_raw_node[\"id\"].replace(\"-\",\".\")\n",
    "        #self.id = parent_id+\".\"+self.key\n",
    "\n",
    "        self.elements = [ApiInterfaceNode(api_documentation_raw_node[\"elements\"][i]) for i in range(len(api_documentation_raw_node[\"elements\"]))]\n",
    "    \n",
    "        if self.node_type == \"api\":\n",
    "            self.api_key = api_documentation_raw_node[\"apiKey\"]\n",
    "            self.api_name = api_documentation_raw_node[\"apiName\"]\n",
    "            self.api_version_key = api_documentation_raw_node[\"versionKey\"]\n",
    "            self.api_version_name = api_documentation_raw_node[\"versionName\"]\n",
    "    \n",
    "        if self.node_type == \"path\":\n",
    "            # no individual attributes for path type\n",
    "            pass\n",
    "\n",
    "        if self.node_type == \"method\":\n",
    "            self.method_summary = api_documentation_raw_node[\"summary\"]\n",
    "            self.method_description = api_documentation_raw_node[\"description\"]\n",
    "\n",
    "        if self.node_type == \"response\":\n",
    "            self.response_description = api_documentation_raw_node[\"description\"]\n",
    "    \n",
    "        if self.node_type == \"payload\":\n",
    "            # no individual attributes for payload type\n",
    "            pass\n",
    "\n",
    "        if self.node_type == \"property\":\n",
    "            self.property_name = api_documentation_raw_node[\"name\"]\n",
    "            self.property_data_type = api_documentation_raw_node[\"dataType\"]\n",
    "            self.property_xpath = remove_data_types_from_xpath(api_documentation_raw_node[\"xpath\"].replace(' ','').replace('\\t','').replace('\\n',''))\n",
    "            self.property_format = api_documentation_raw_node[\"format\"]\n",
    "            self.property_pattern = api_documentation_raw_node[\"pattern\"]\n",
    "            self.property_description = api_documentation_raw_node[\"description\"]\n",
    "        \n",
    "    def is_type(self, node_type: str):\n",
    "        \"\"\"\n",
    "        Returns true, if the node's type is equal the passed type, else false.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node_type : str\n",
    "            type that should be compared with the type of the node\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        True or False\n",
    "        \"\"\"\n",
    "        return self.node_type == node_type\n",
    "  \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a JSON object as string containing all attributes of the node\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        JSON object as string containing all attributes of the node\n",
    "        \"\"\"\n",
    "        json_dict = {}\n",
    "        json_dict[\"key\"] = self.key\n",
    "        json_dict[\"value\"] = self.value\n",
    "        json_dict[\"id\"] = self.id\n",
    "        json_dict[\"type\"] = self.node_type\n",
    "        json_dict[\"number_of_elements\"] = len(self.elements)\n",
    "\n",
    "        if self.node_type == \"api\":\n",
    "            json_dict[\"apiKey\"] = self.api_key\n",
    "            json_dict[\"apiName\"] = self.api_name\n",
    "            json_dict[\"versionKey\"] = self.api_version_key\n",
    "            json_dict[\"versionName\"] = self.api_version_name\n",
    "    \n",
    "        if self.node_type == \"path\":\n",
    "            # no individual attributes for path type\n",
    "            pass\n",
    "\n",
    "        if self.node_type == \"method\":\n",
    "            json_dict[\"summary\"] = self.method_summary\n",
    "            json_dict[\"description\"] = self.method_description\n",
    "\n",
    "        if self.node_type == \"response\":\n",
    "            json_dict[\"description\"] = self.response_description\n",
    "    \n",
    "        if self.node_type == \"payload\":\n",
    "            # no individual attributes for payload type\n",
    "            pass\n",
    "\n",
    "        if self.node_type == \"property\":\n",
    "            json_dict[\"name\"] = self.property_name \n",
    "            json_dict[\"dataType\"] = self.property_data_type \n",
    "            json_dict[\"xpath\"] = self.property_xpath \n",
    "            json_dict[\"format\"] = self.property_format\n",
    "            json_dict[\"pattern\"] = self.property_pattern\n",
    "            json_dict[\"description\"] = self.property_description\n",
    "    \n",
    "        return json.dumps(json_dict)\n",
    "\n",
    "def load_and_parse_api(path: str):\n",
    "    \"\"\"\n",
    "    Loads and parses an API tree model file located under the passed path and converts it structure into a structure of ApiInterfaceNodes.\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the API tree model file\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    ApiInterfaceNode representing the root of the loaded and parsed API tree model\n",
    "    \"\"\"\n",
    "    with open(path,\"r\",encoding=\"utf-8\") as json_file:\n",
    "        json_api = json.load(json_file)\n",
    "    return ApiInterfaceNode(json_api)\n",
    "\n",
    "def load_and_parse_apis_from_directory(path: str, limit: int = None):\n",
    "    \"\"\"\n",
    "    Loads and parses multiple API tree model files located in the specified directory.\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to directory where the API tree model files are located\n",
    "      \n",
    "    limit : int\n",
    "        Optional limit. If specified, only the first 'n' API tree model files are loaded and parsed\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    List of ApiInterfaceNodes where each node represents the root of a loaded and parsed API tree model\n",
    "    \"\"\"\n",
    "    apis = []\n",
    "    if limit:\n",
    "        filesnames = os.listdir(path)[:limit]\n",
    "    else:\n",
    "        filesnames = os.listdir(path)\n",
    "\n",
    "    for filename in tqdm(filesnames):\n",
    "        if filename.endswith(\".json\"):\n",
    "            apis.append(load_and_parse_api(os.path.join(path,filename)))\n",
    "    return apis\n",
    "\n",
    "def extract_nodes(node: ApiInterfaceNode, node_type: str):\n",
    "    \"\"\"\n",
    "    Extracts all nodes matching the passed node type from the passed API tree model.\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : ApiInterfaceNode\n",
    "      API tree model (input)\n",
    "    node_type : str\n",
    "      The type of the node that should be extracted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of ApiInterfaceNodes matching the passed node type\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    if node.node_type == node_type:\n",
    "        nodes.append(node)\n",
    "    for element in node.elements:\n",
    "        nodes += extract_nodes(element, node_type)\n",
    "    return nodes\n",
    "\n",
    "def extract_nodes_in_apis(nodes: [ApiInterfaceNode], node_type: str):\n",
    "    \"\"\"\n",
    "    Extracts all nodes matching the passed node type from the passed list of API tree models.\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : [ApiInterfaceNodes]\n",
    "      List of API tree models (input)\n",
    "    node_type : str\n",
    "      The type of the node that should be extracted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of ApiInterfaceNodes matching the passed node type\n",
    "    \"\"\"\n",
    "    extracted_nodes = []\n",
    "    for node in nodes:\n",
    "        extracted_nodes += extract_nodes(node,node_type)\n",
    "    return extracted_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a630a1-9c87-4b8f-b9ef-453208c85613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse API tree models\n",
    "apis = load_and_parse_apis_from_directory(input_path,limit=api_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7a01b-7f22-4db1-87c5-4721cc401d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract payload nodes\n",
    "payload_nodes = extract_nodes_in_apis(apis,node_type=\"payload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ffcbf-d593-4ecc-bd1d-faa881f2cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of payload nodes: \",len(payload_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1efee3-c072-4c1b-9d66-3bc2be565a55",
   "metadata": {},
   "source": [
    "# Create QA-Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70ba46-9a22-40dc-a532-f72c9a48d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswer:\n",
    "    \"\"\"\n",
    "    Represents a question-answer pair consisting of a unique identifier, a question, its length (number of tokens), the answer of the question, and the character based index of the start of the answer within the context.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    id : str\n",
    "        unique identifier of a question-answer pair\n",
    "    question : str\n",
    "        question text\n",
    "    question_length : int\n",
    "        number of tokens of question text\n",
    "    answer : str\n",
    "        answer text\n",
    "    answer_start : int\n",
    "        position (index) of the first character of the answer text within original context\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    as_dict():\n",
    "        Converts the question-answer pair into a Python dictionary following the structure for QA pairs recommended in https://huggingface.co/course/chapter7/7?fw=pt  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, question, question_length, answer, answer_position_in_index):\n",
    "        \"\"\"\n",
    "        Constructs a question-answer pair having the passed parameters\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        question : str\n",
    "            question text\n",
    "        question_length : int\n",
    "            number of tokens of question text\n",
    "        answer : str\n",
    "            answer text\n",
    "        answer_position_in_index : int\n",
    "            position (index) of the first character of the answer text within original context\n",
    "        \"\"\"\n",
    "        self.id = uuid.uuid4().hex;\n",
    "        self.question = question\n",
    "        self.question_length = question_length\n",
    "        self.answer = answer\n",
    "        self.answer_start = answer_position_in_index\n",
    "  \n",
    "    def as_dict(self):\n",
    "        \"\"\"\n",
    "        Converts this question-answer pair into a Python dictionary following the structure for QA pairs recommended in https://huggingface.co/course/chapter7/7?fw=pt\n",
    "        {\n",
    "            'id': ....,\n",
    "            'question': ....,\n",
    "            'question_length': .....,\n",
    "            'answers':{\n",
    "                'text': [....],\n",
    "                'answer_start : [....]\n",
    "            }\n",
    "        }\n",
    "        Note that 'answers.text' and 'answers.answer_start' both are lists as in classical NL QA a question might have multiple answers. In our case, every question has exactly one answer, thus, one item per list.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Python dictionary\n",
    "        \"\"\"\n",
    "        a = {}\n",
    "        a[\"text\"] = [self.answer]\n",
    "        a[\"answer_start\"] = [self.answer_start]\n",
    "        q = {}\n",
    "        q[\"id\"] = self.id\n",
    "        q[\"question\"] = self.question\n",
    "        q[\"question_length\"] = self.question_length\n",
    "        q[\"answers\"] = a\n",
    "        return q\n",
    "\n",
    "class QuestionAnswerSample:\n",
    "    \"\"\"\n",
    "    Represents a question-answer sample consisting of a unique identifier, a title, a context, and multiple question-answer pairs extracted from the context \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    id : str\n",
    "        unique identifier of the sample\n",
    "    title : str\n",
    "        title of the sample\n",
    "    context : str\n",
    "        context (text)\n",
    "    questionAnswers : [QuestionAnswer]\n",
    "        question-answer pairs extracted from the context \n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    __str__():\n",
    "        Converts the sample including its question-answer pairs into a JSON structure following the structure for QA pairs recommended in https://huggingface.co/course/chapter7/7?fw=pt\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, context, questionAnswers: list, title = None):\n",
    "        \"\"\"\n",
    "        Constructs a question-answer sample having the passed parameters\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        context : str\n",
    "            context (text)\n",
    "        questionAnswers : [QuestionAnswer]\n",
    "            list of question-answer pairs\n",
    "        title : str\n",
    "            optional title of the sample\n",
    "        \"\"\"\n",
    "        self.id = uuid.uuid4().hex;\n",
    "        for qa in questionAnswers:\n",
    "            qa.id = self.id +\"_\"+qa.id\n",
    "\n",
    "        self.title = title;\n",
    "        self.context = context\n",
    "        self.questionAnswers = questionAnswers\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Converts the sample including its question-answer pairs into a JSON structure following the structure for QA pairs recommended in https://huggingface.co/course/chapter7/7?fw=pt\n",
    "        {\n",
    "            \"id\": ....,\n",
    "            \"title\": ....,\n",
    "            \"context\": ....,\n",
    "            \"questions\": [ //see QuestionAnswer.as_dict()]\n",
    "        }\n",
    "        \"\"\"\n",
    "        json_dict = {}\n",
    "        json_dict[\"id\"] = self.id\n",
    "        json_dict[\"title\"] = self.title\n",
    "        json_dict[\"context\"] = self.context\n",
    "        json_dict[\"questions\"] = [x.as_dict() for x in self.questionAnswers]\n",
    "        return json.dumps(json_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431fdbf-4f9a-4139-92a7-fcb2e32b428a",
   "metadata": {},
   "source": [
    "## Prepare Pre-Trained Tokenizer for Length Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39150aa-dac0-4b72-8cbb-4b583fc5a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03f9c0-cda7-4453-8b02-21a18f29104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(input: str):\n",
    "    \"\"\"\n",
    "    Calculates and returns the length (i.e. number of tokens) of the passed input string\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input : str\n",
    "        Input string whose length should be calculated\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Number of tokens\n",
    "    \"\"\"\n",
    "    return len(tokenizer.encode(input, add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23448e1-97b6-46f0-9ed9-60d7b71b7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tokenizer\n",
    "test_string = \"account.user.name\"\n",
    "get_length(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab87cd8-fb86-49c2-8902-60952d1c20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing length limitations\n",
    "s = \" \".join([str(x) for x in range(99999)])\n",
    "get_length(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837aec8-5a23-4e00-8675-9e65c220ee70",
   "metadata": {},
   "source": [
    "## Methods for Creating Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290479c-62ef-441b-8eb3-61a932c5e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xpaths(node: ApiInterfaceNode):\n",
    "    \"\"\"\n",
    "    Extracts all XPaths from the API sub tree where the passed ApiInterfaceNode is the root of this tree. Note that the root node will not be processed (only its children) and all nodes, except of the root node, must be type of 'property'.\n",
    "    The method returns the list of extracted XPaths.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : ApiInterfaceNode\n",
    "        root node of the API sub tree whose XPaths should be extracted\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of extracted XPaths\n",
    "    \"\"\"\n",
    "    xpaths = []\n",
    "    for element in node.elements:\n",
    "        # if node is type of array, object or unknown with childs\n",
    "        if element.property_data_type == \"array\" or element.property_data_type == \"object\" or ((element.property_data_type == \"unknown\" or element.property_data_type == None) and len(element.elements) > 0):\n",
    "            xpaths += extract_xpaths(element)\n",
    "            \n",
    "        # if node is type of string, num, int, bool, or unknown without childs \n",
    "        else:\n",
    "            xpaths.append(element.property_xpath)\n",
    "    return xpaths\n",
    "\n",
    "\n",
    "def filter_xpaths(xpaths: list, max_depth: int):\n",
    "    \"\"\"\n",
    "    Removes all XPaths from the passed list that exceed the specified maximum depth and returns the modified list.\n",
    "    Example: 'users.address.street' has a depth of 3.\n",
    "    If 'max_depth' is None, the passed list will be returned without any removal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xpaths : [str]\n",
    "        List of XPaths (strings)\n",
    "    max_depth : int\n",
    "        maximum depth (can be None)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Modified list of XPaths\n",
    "    \"\"\"\n",
    "    filtered_xpaths = []\n",
    "    for xpath in xpaths:\n",
    "        if max_depth == None or len(xpath.split(\".\")) <= max_depth:\n",
    "            filtered_xpaths.append(xpath)\n",
    "    return filtered_xpaths\n",
    "\n",
    "\n",
    "def build_context_string(xpaths: list, sort_by_name: bool = False, shuffle: bool = False):\n",
    "    \"\"\"\n",
    "    Removes duplicate XPaths from the passed XPath list, optionally sort (ascending order) or shuffle the list and finally concatenates the remaining XPath items to a string with spaces as speparator between items.\n",
    "    The method returns this resulting string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xpaths : [string]\n",
    "        list of XPaths\n",
    "    sort_by_name : bool\n",
    "        if set to True (default value is False), the method will sort the list of XPath items in ascending order\n",
    "    shuffle : bool\n",
    "        if set to True (default value is False), the method will shuffle the list of XPath items\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String containing the concatenated XPath items\n",
    "    \"\"\"\n",
    "    \n",
    "    assert not shuffle and sort_by_name, \"Cannot shuffle and sort xpaths at the same time\"\n",
    "    \n",
    "    xpaths_without_duplicate_items = []\n",
    "    deduplication_set = set()\n",
    "    \n",
    "    for xpath in xpaths:\n",
    "        if not xpath in deduplication_set:\n",
    "            xpaths_without_duplicate_items.append(xpath)\n",
    "            deduplication_set.add(xpath)\n",
    "            \n",
    "    # shuffle (if enabled)\n",
    "    if shuffle:\n",
    "        random.shuffle(xpaths_without_duplicate_items)\n",
    "        \n",
    "    # sort by name (if enabled)\n",
    "    if sort_by_name:\n",
    "        xpaths_without_duplicate_items.sort()\n",
    "    \n",
    "    return \" \".join(xpaths_without_duplicate_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f35ef3-11e6-4508-8738-fbe5005f22c9",
   "metadata": {},
   "source": [
    "## Methods for Creating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b915c-50d2-4dc2-a4f3-86559855eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inline_uris(text: str):\n",
    "    \"\"\"\n",
    "    Removes URIs from the passed string and returns the modified string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        input string that should be scanned for URIs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Modified string\n",
    "    \"\"\"\n",
    "    tokens = text.split(' ')\n",
    "    for token in tokens:\n",
    "        if \"http:\" in token.lower() or \"https:\" in token.lower():\n",
    "            text = text.replace(token,\" \")\n",
    "    return text\n",
    "\n",
    "def truncate_question(question: str, max_question_length: int):\n",
    "    \"\"\"\n",
    "    Truncates the passed question (string) if the number of tokens exceeds the passed maximum question length. If the passed question is too long, the method tries to split it into sentences and concatenates these sentences\n",
    "    until maximum question length is exceeded. The method returns the truncated question, its length (number of tokens), and the whether it has been  truncated (True) or not (False)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    question : str\n",
    "        Original question that should be truncated\n",
    "    max_question_length : int\n",
    "        Maximum number of tokens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The truncated question, its length, and whether it has been truncated (True) or not (False)\n",
    "    \n",
    "    \"\"\"\n",
    "    # determine length of original question\n",
    "    length = get_length(question)\n",
    "    \n",
    "    # if question length (number of tokens determined by tokenizer) does not exceed max. question length\n",
    "    if length <= max_question_length:\n",
    "        # return question without any modifications\n",
    "        return question, length, False\n",
    "    \n",
    "    # if question length exceeds max. question length\n",
    "    else:\n",
    "        # (Try to) split question into sentences\n",
    "        sentences = question.split(\".\")\n",
    "        \n",
    "        # calculate length for each sentende \n",
    "        sentences_and_lengths = [(x,get_length(x)) for x in sentences] # generates a tuple of (sentence,length) for each sentence\n",
    "        \n",
    "        # reset question and length\n",
    "        question = \"\"\n",
    "        length = 0\n",
    "        \n",
    "        # concatenate sentences until max. question length is reached\n",
    "        for sentence in sentences_and_lengths:\n",
    "            sentence_text = sentence[0]\n",
    "            sentence_length = sentence[1]\n",
    "            \n",
    "            # if sentence is not empty and new total length does not exceed max. question length\n",
    "            if sentence_text is not None and length + sentence_length < max_question_length:\n",
    "                question = question + sentence_text+\".\"\n",
    "                length = length + sentence_length + 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return question, get_length(question), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e4a84-4b10-4448-8475-37517eb38c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test truncate_question\n",
    "question = \"This is a short example. We want to test, whether truncate_question works as expected. Hello World\"\n",
    "truncate_question(question,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f4a28-08b3-40b0-8a9c-3f561bb6a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_length(\"This is a short\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e2a2c-5afb-40d8-a25c-71255f6b3c9d",
   "metadata": {},
   "source": [
    "## Methods for Creating Question-Answer Pairs and Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b31e2-f12a-4d2e-b690-f76517d80c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_start(context: str,answer_text: str):\n",
    "    \"\"\"\n",
    "    Returns the position of the first character of the passed answer text in the specified context or None if the answer is not in the context.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    context : str\n",
    "        context\n",
    "    answer_text:\n",
    "        answer text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Position of the first character of the answer text or None if the answer is not in the context\n",
    "    \"\"\"\n",
    "    \n",
    "    position = 0\n",
    "    for property in context.split():\n",
    "        if answer_text == property:\n",
    "            return position\n",
    "        else:\n",
    "            position += len(property)\n",
    "        position+=1 # for each space\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed336e23-f372-4cd5-9f19-11602bae5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test get_answer_start\n",
    "context = \"user.address user.address.street user.address.city user\"\n",
    "get_answer_start(context,\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac936c3-e141-4cd6-baac-007f064c8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,char in enumerate(context):\n",
    "    print(i,\" \",char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ed41e-0679-4d7c-b270-723a0d33ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_answer_pairs(node: ApiInterfaceNode, context: str, min_question_length: int = None , max_question_length: int = None, remove_uris: bool = False, max_depth: int = None):\n",
    "    \"\"\"\n",
    "    Create and returns a list of Question-Answer pairs deduced from the passed API sub tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    context : str\n",
    "        context, required for calculating the position (character-based index) of the answer\n",
    "    min_question_length : int\n",
    "        Optional parameter (default is None) that specifies the minimum length (number of tokens) that a question must have. If the parameter is None, the minimum length is one token\n",
    "    max_question_length : int\n",
    "        Optional parameter (default is None) that specifies the maximum length (number of tokens) that a question may have. If the parameter is None, the maximum length is unlimited\n",
    "    remove_uris : bool\n",
    "        Optional parameter (default is False) indicating whether URIs should be removed from questions\n",
    "    max_depth : int\n",
    "        Optional parameter (default is None) that specifies the maximum depth that an answer (i.e. the XPath without root element) may have. If the parameter is None, there is no depth limitation\n",
    "        \n",
    "    Results\n",
    "    -------\n",
    "    List of created Question-Answer pairs\n",
    "    \"\"\"\n",
    "    question_answer_pairs = []\n",
    "    \n",
    "    valid = True\n",
    "    \n",
    "    # check whether property has a description\n",
    "    if not node.property_description:\n",
    "        global cnt_no_property_description\n",
    "        cnt_no_property_description += 1\n",
    "        valid = False\n",
    "    \n",
    "    # check whether XPath does not exceed max. depth\n",
    "    if max_depth is not None and len(node.property_xpath.split(\".\")) > max_depth:\n",
    "        global cnt_too_deep_property_xpath \n",
    "        cnt_too_deep_property_xpath += 1\n",
    "        valid = False\n",
    "        \n",
    "    # check whether all constraints so far are satisfied and property is primitive type (string, number, integer, boolean or unknown without children)\n",
    "    if valid and (node.property_data_type == \"string\" \n",
    "        or node.property_data_type == \"number\" \n",
    "        or node.property_data_type == \"integer\" \n",
    "        or node.property_data_type == \"boolean\"\n",
    "        or (node.property_data_type == \"unknown\" and len(node.elements) == 0)):\n",
    "        \n",
    "        description = node.property_description\n",
    "\n",
    "        \n",
    "        # Step 1 (optional): Remove inline URIs:\n",
    "        if remove_uris:\n",
    "            description = remove_inline_uris(description)\n",
    "        \n",
    "        # Step 2: Remove unecessary whitespaces\n",
    "        while '  ' in description:\n",
    "            description = description.replace('  ',' ')\n",
    "        \n",
    "        # Step 3 (optional): Truncate description (Note: truncate_question might return an empty question!)\n",
    "        if max_question_length is not None:\n",
    "            description, length, truncated = truncate_question(description, max_question_length)\n",
    "            if truncated:\n",
    "                global cnt_too_long_property_description_but_truncated\n",
    "                cnt_too_long_property_description_but_truncated += 1\n",
    "        else:\n",
    "            length = get_length(question)\n",
    "        \n",
    "        # Finally check whether description is either empty (if there is NO min_question_length)\n",
    "        if min_question_length is None and not description:\n",
    "            global cnt_too_long_property_description\n",
    "            cnt_too_long_property_description += 1\n",
    "            valid = False\n",
    "        \n",
    "        # ... or (if there is a min_question_length) whether the description is shorten than the minimum required number of tokens\n",
    "        if min_question_length is not None and length < min_question_length:\n",
    "            global cnt_too_short_property_description \n",
    "            cnt_too_short_property_description += 1\n",
    "            valid = False\n",
    "        \n",
    "        # if all constraints are satisfied \n",
    "        if valid:\n",
    "            \n",
    "            # Build answer:\n",
    "            answer = node.property_xpath\n",
    "            \n",
    "            # Calculate answer position in context\n",
    "            answer_start = get_answer_start(context,answer)\n",
    "            # if answer is in the context\n",
    "            if answer_start != None:\n",
    "                # Create Question-Answer pair and add it to list\n",
    "                question_answer = QuestionAnswer(description,length,answer,answer_start)\n",
    "                question_answer_pairs.append(question_answer)\n",
    "            else:\n",
    "                global cnt_answer_not_in_context\n",
    "                cnt_answer_not_in_context += 1\n",
    "                print(\"Error: Answer not in context\")\n",
    "                print(\"ID: \",node.id)\n",
    "                print(\"Context: \",context)\n",
    "                print(\"Answer: \", answer)\n",
    "    \n",
    "    \n",
    "    # recursive call if node is type of array, object, or unknown with childs\n",
    "    if node.property_data_type == \"array\" or node.property_data_type == \"object\" or ((node.property_data_type == \"unknown\" or node.property_data_type == None) and len(node.elements) > 0):\n",
    "        for element in node.elements:\n",
    "            question_answer_pairs += create_question_answer_pairs(element,context,min_question_length,max_question_length, remove_uris, max_depth)\n",
    "    \n",
    "    return question_answer_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1a399-fcd9-4aea-9e60-35d525162259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_answer_samples_for_payload(schema_root_node: ApiInterfaceNode, min_question_length: int = None , max_question_length: int = None, remove_uris: bool = False, max_depth: int = None, max_questions_per_sample: int = None, sort_by_name: bool = False, shuffle_context: bool = False):\n",
    "    \"\"\"\n",
    "    Creates and returns one or multiple Question-answer samples for the passed schema root node. The decision whether one or multiple samples are created depends on the 'max_question_per_sample' threshold as well as the size (number of properties) of the payload.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    schema_root_node : ApiInterfaceNode\n",
    "        Root node of the schema ($)\n",
    "    min_question_length : int\n",
    "        Optional parameter (default is None) that specifies the minimum length (number of tokens) that a question must have. If the parameter is None, the minimum length is one token\n",
    "    max_question_length : int\n",
    "        Optional parameter (default is None) that specifies the maximum length (number of tokens) that a question may have. If the parameter is None, the maximum length is unlimited\n",
    "    remove_uris : bool\n",
    "        Optional parameter (default is False) indicating whether URIs should be removed from questions\n",
    "    max_depth : int\n",
    "        Optional parameter (default is None) that specifies the maximum depth that an XPath (as answer as well as in context) may have. If the parameter is None, there is no depth limitation\n",
    "    max_questions_per_sample : int\n",
    "        Optional parameter (default is None) that specifies the maximum number of Question-Answer pairs per sample. The method distributes the Question-Answer pairs to mulitple samples if this limit is exceeded.\n",
    "    sort_by_name : bool\n",
    "        if set to True (default value is False), the method will sort XPaths in context in ascending order\n",
    "    shuffle : bool\n",
    "        if set to True (default value is False), the method will shuffle XPaths in context\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of created Question-Answer samples (even if one sample is created, it is a list)\n",
    "    \"\"\"\n",
    "    # Build context\n",
    "    xpaths = extract_xpaths(schema_root_node)\n",
    "    if max_depth:\n",
    "        xpaths = filter_xpaths(xpaths,max_depth)\n",
    "    context = build_context_string(xpaths,sort_by_name,shuffle_context)\n",
    "    \n",
    "    # Check whether context contains XPaths\n",
    "    if context:\n",
    "        question_answer_pairs = create_question_answer_pairs(schema_root_node, context, min_question_length, max_question_length, remove_uris, max_depth)\n",
    "        \n",
    "        # Check if at least one Question-Answer pair has been created:\n",
    "        if question_answer_pairs:\n",
    "            if max_questions_per_sample is not None:\n",
    "                samples = []\n",
    "                \n",
    "                while question_answer_pairs:\n",
    "                    counter = 0\n",
    "                    partial_question_answer_pairs = []\n",
    "                    while len(question_answer_pairs) > 0 and counter < max_questions_per_sample:\n",
    "                        partial_question_answer_pairs.append(question_answer_pairs.pop())\n",
    "                        counter += 1\n",
    "                    sample = QuestionAnswerSample(context, partial_question_answer_pairs, schema_root_node.id)\n",
    "                    samples.append(sample)\n",
    "                \n",
    "                if len(samples) > 1:\n",
    "                    global cnt_split_samples\n",
    "                    cnt_split_samples += 1\n",
    "                return samples\n",
    "            else:\n",
    "                sample = QuestionAnswerSample(context, question_answer_pairs, schema_root_node.id)\n",
    "                return [sample]\n",
    "    else:\n",
    "        global cnt_no_context\n",
    "        cnt_no_context += 1\n",
    "        \n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee6602-f062-47ba-9f38-979b98896fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cnt = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "\n",
    "for api in tqdm(apis):\n",
    "    if int(api.api_key) in excluded_api_keys:\n",
    "        print(\"Skip \",api.api_name,\" (\",api.api_key,\")\")\n",
    "        continue\n",
    "\n",
    "    question_cnt_per_api = 0\n",
    "    payload_cnt_per_api = 0\n",
    "    samples = []\n",
    "\n",
    "    for i in range(original_retakes):\n",
    "        for payload_node in extract_nodes(api,node_type=\"payload\"):\n",
    "            payload_cnt_per_api+=1\n",
    "            if len(payload_node.elements) == 1:\n",
    "                root_node = payload_node.elements[0]\n",
    "                s = create_question_answer_samples_for_payload(root_node,min_question_length,max_question_length,remove_uris,max_depth,max_questions_per_sample, sort_by_name, False)\n",
    "                if s:\n",
    "                    samples+= s\n",
    "\n",
    "    for i in range(shuffled_retakes):\n",
    "        for payload_node in extract_nodes(api,node_type=\"payload\"):\n",
    "            payload_cnt_per_api+=1\n",
    "            if len(payload_node.elements) == 1:\n",
    "                root_node = payload_node.elements[0]\n",
    "                s = create_question_answer_samples_for_payload(root_node,min_question_length,max_question_length,remove_uris,max_depth,max_questions_per_sample, False, True)\n",
    "                if s:\n",
    "                    samples+= s\n",
    "\n",
    "    if samples:\n",
    "        for sample in samples:\n",
    "            question_cnt_per_api += len(sample.questionAnswers)\n",
    "            question_cnt += len(sample.questionAnswers)\n",
    "        results.append({\n",
    "            \"samples\":samples,\n",
    "            \"api_key\":api.api_key,\n",
    "            \"api_name\":api.api_name,\n",
    "            \"api_version_key\":api.api_version_key,\n",
    "            \"api_version_name\":api.api_version_name,\n",
    "            \"payload_cnt_per_api\":payload_cnt_per_api,\n",
    "            \"question_cnt_per_api\":question_cnt_per_api\n",
    "        })\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "       \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7273a9-841d-4714-bf09-39a2e0543c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(results, key=lambda item: item[\"question_cnt_per_api\"],reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8bd49-38ce-4da1-b360-4df3c9456371",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [[] for i in range(number_of_chunks)]\n",
    "\n",
    "with open(output_path+datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")+\".log.csv\",\"w\") as log_file:\n",
    "    log_file.write(\"API Key;API Name;API Version Key; API Version;#Payloads;#Samples;#Questions;Out File\\n\")\n",
    "    for result in sorted_results:\n",
    "        smallest_chunk_index = 0\n",
    "        smallest_chunk_size = None\n",
    "        for i in range(number_of_chunks):\n",
    "            num_questions = 0\n",
    "            for sample in chunks[i]:\n",
    "                num_questions+=result[\"question_cnt_per_api\"]\n",
    "            if smallest_chunk_size == None or num_questions < smallest_chunk_size:\n",
    "                smallest_chunk_size = num_questions\n",
    "                smallest_chunk_index = i\n",
    "        chunks[smallest_chunk_index]+= result[\"samples\"]\n",
    "        filename = str(smallest_chunk_index)+\".json\"\n",
    "\n",
    "        log_file.write(str(result[\"api_key\"])+\";\"+str(result[\"api_name\"])+\";\"+str(result[\"api_version_key\"])+\";\"+str(result[\"api_version_name\"])+\";\"+str(result[\"payload_cnt_per_api\"])+\";\"+str(len(result[\"samples\"]))+\";\"+str(result[\"question_cnt_per_api\"])+\";\"+filename+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6bb44-8bc7-4742-a629-aa1f635851c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Questions: \",question_cnt)\n",
    "print(\"# Payloads without context: \", cnt_no_context)\n",
    "print(\"# Properties without description: \", cnt_no_property_description)\n",
    "print(\"# Properties with too long descriptions (but could be truncated): \", cnt_too_long_property_description_but_truncated)\n",
    "print(\"# Properties with too long descriptions (could not be truncated): \", cnt_too_long_property_description)\n",
    "print(\"# Properties with too short descriptions: \", cnt_too_short_property_description)\n",
    "print(\"# Properties with too deep XPaths: \", cnt_too_deep_property_xpath)\n",
    "print(\"# Original samples that have been split into multiple samples: \", cnt_split_samples)\n",
    "print(\"# Errors: Answer not in context: \", cnt_answer_not_in_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05159794-7b3b-4833-84de-5de9e748b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle samples\n",
    "for i in range(number_of_chunks):\n",
    "    random.shuffle(chunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e254d1b-cd01-4ca2-ba8a-21385a1abbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print chunks\n",
    "for i in range(number_of_chunks):\n",
    "    q_cnt = 0\n",
    "    for sample in chunks[i]:\n",
    "            q_cnt += len(sample.questionAnswers)\n",
    "    print(i,\": \",len(chunks[i]),\" samples / \",q_cnt,\" questions (\", (q_cnt/question_cnt)*100,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1772ede-6b4f-4226-82a7-f461b9bdef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write chunks\n",
    "for i in range(number_of_chunks):\n",
    "  with open(output_path+str(i)+\".json\",\"w\") as file:\n",
    "    for sample in chunks[i]:\n",
    "      file.write(str(sample))\n",
    "      file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1afabe-6402-4991-8acb-f207ab8000f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write validation set\n",
    "validation_index = 2\n",
    "with open(output_path+\"validation.json\",\"w\") as file:\n",
    "    for sample in chunks[validation_index]:\n",
    "        file.write(str(sample))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743001a-8ddc-442e-b4c2-5af4dfc6a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write test set\n",
    "test_index = 9\n",
    "with open(output_path+\"test.json\",\"w\") as file:\n",
    "    for sample in chunks[test_index]:\n",
    "        file.write(str(sample))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194b81b-942b-47a7-8f5c-a0090ea017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [0,1,3,4,5,6,7,8]\n",
    "train_samples = []\n",
    "for i in train_indices:\n",
    "    train_samples += chunks[i]\n",
    "random.shuffle(train_samples)\n",
    "\n",
    "with open(output_path+\"train.json\",\"w\") as file:\n",
    "    for sample in train_samples:\n",
    "        file.write(str(sample))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8eb7a8-01e4-47d0-98b8-7fd17ad1c2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
